**RUGD: Robot Unstructured Ground Driving Dataset** is a dataset for a semantic segmentation task. It is used in the safety and robotics industries. 

The dataset consists of 7436 images with 50032 labeled objects belonging to 24 different classes including *tree*, *sky*, *grass*, and other: *mulch*, *gravel*, *bush*, *pole*, *log*, *building*, *vehicle*, *container*, *fence*, *asphalt*, *water*, *rock*, *sign*, *concrete*, *rock-bed*, *picnic-table*, *dirt*, *bridge*, *sand*, *person*, and *bicycle*.

Images in the RUGD dataset have pixel-level semantic segmentation annotations. All images are labeled (i.e. with annotations). There are 3 splits in the dataset: *train* (4779 images), *test* (1924 images), and *val* (733 images). Alternatively, the dataset could be split into 4 general environment categories: ***trail*** (4843 images), ***park*** (1640 images), ***creek*** (836 images), and ***village*** (117 images). The dataset was released in 2019 by the <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">US joint research group</span>.

Here are the visualized examples for the classes:

[Dataset classes](https://github.com/dataset-ninja/rugd/raw/main/visualizations/classes_preview.webm)
