**RUGD: Robot Unstructured Ground Driving Dataset** is a dataset for a semantic segmentation task. It is used in the robotics industry. 

The dataset consists of 7436 images with 50032 labeled objects belonging to 25 different classes including *tree*, *sky*, *grass*, and other: *mulch*, *gravel*, *bush*, *pole*, *log*, *building*, *vehicle*, *container*, *fence*, *asphalt*, *water*, *rock*, *sign*, *concrete*, *rock-bed*, *picnic-table*, *dirt*, *bridge*, *sand*, *person*, *bicycle*, and *void*.

Images in the RUGD dataset have pixel-level semantic segmentation annotations. All images are labeled (i.e. with annotations). There are no pre-defined <i>train/val/test</i> splits in the dataset. Alternatively, the dataset could be split into 4 general environment categories: ***trail*** (4843 images), ***park*** (1640 images), ***creek*** (836 images), and ***village*** (117 images). The dataset was released in 2019 by the US joint research group.

<img src="https://github.com/dataset-ninja/rugd/raw/main/visualizations/poster.png">
